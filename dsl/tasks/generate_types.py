import sys
from google.protobuf import descriptor_pb2
import os
import re
from dataclasses import dataclass
from fnmatch import fnmatch

_SKIP_FILES = [
        'services/remote_service.proto',
        'services/mission_service.proto',
        'services/flight_log_service.proto',
        'messages/compute_payload.proto',
        'testing/testing.proto'
        ]

def generate(output_dir):
    root = os.getenv('ROOTPATH')
    if not root:
        root = '../../'
    protocol_fds = descriptor_pb2.FileDescriptorSet()
    with open(f'{root}protocol/protocol.desc', "rb") as f:
        protocol_fds.MergeFromString(f.read())
    init_lines = [] # Lines to go in __init__.py for the output module
    for file in protocol_fds.file:
        if file.name in _SKIP_FILES:
            continue # Don't generate types for this file!
        splits = file.name.split('/')
        name = splits[-1].split('.')[0]
        # Generate folders if they don't exist
        path = f'{output_dir}/'
        if len(splits) > 0:
            folders = splits[:-1]
            for folder in folders:
                path += folder + '/'
                if not os.path.isdir(path):
                    os.mkdir(path)
        # Map to find comments in the source code for eventual auto-documentation
        location_map = {tuple(loc.path): loc for loc in file.source_code_info.location}
        with open(f'{path}{name}.py', 'w') as f:
            # Header lines
            lines = []
            lines.append("#####################################################################")
            lines.append("# NOTE: THIS FILE IS AUTOGENERATED BY GENERATE_TYPES.PY. DO NOT EDIT!")
            lines.append("#####################################################################")
            lines.append("from task.base import Action, Datatype")
            lines.append("from dataclasses import dataclass")
            lines.append("from enum import Enum")
            lines.append("from google.protobuf.json_format import ParseDict, MessageToDict")
            lines.append("from google.protobuf.timestamp_pb2 import Timestamp as ProtoTimestamp")
            for dependency in file.dependency:
                lines.append(f"import {output_dir.replace('./', '')}.{dependency.replace('/', '.')[:-6]}")
            lines.append("")
            # Write enums
            if len(file.enum_type):
                lines.append("''' Enums '''")
            for i, enum in enumerate(file.enum_type):
                lines.append(f"class {enum.name}(Enum):")
                lines.append(f"{get_comments((5, i), location_map)}")
                for j, value in enumerate(enum.value):
                    lines.append(f"    {value.name} = {value.number}")
                    lines.append(f"    {get_comments((5, i, 2, j), location_map)}")
                lines.append("")
            # Write messages
            if len(file.message_type):
                lines.append("''' Messages '''")
            field_map = {}
            for i, message in enumerate(file.message_type):
                if 'Request' in message.name:
                    field_map[message.name] = (get_fields(message.field), i) # Cache parameters for later
                    continue # Skip this if it's an RPC request; they are not in the Python API
                lines.append("@dataclass")
                lines.append(f"class {message.name}(Datatype):")
                lines.append(f"{get_comments((4, i), location_map)}")
                fields = get_fields(message.field)
                for field_name, typ, path_type, index in fields:
                    lines.append(f"    {field_name}: {typ}")
                    lines.append(f"    {get_comments((4, i, path_type, index), location_map)}")
                lines.append("")
                lines.append("    def get_type_url():")
                lines.append(f"        return 'type.googleapis.com/{file.package}.{message.name}'")
                lines.append("")
            # Write services
            for i, service in enumerate(file.service):
                lines.append(f"''' {service.name} methods '''")
                lines.append(f"{get_comments((6, i), location_map)}")
                lines.append(f"from bindings.python.{file.name.replace('/', '.').replace('proto', '_pb2')} as {service.name.lower()}_proto")
                lines.append("")
                for j, method in enumerate(service.method):
                    lines.append("@register_action")
                    lines.append(f"class {method.name}(Action):")
                    lines.append(f"{get_comments((6, i, 2, j), location_map)}")
                    # Retrieve the path data from the first time we traversed the messages
                    fields, message_index = field_map[f"{method.name}Request"]
                    for k, (field_name, typ, path_type, index) in enumerate(fields):
                        lines.append(f"    {field_name}: {typ}")
                        lines.append(f"    {get_comments((4, message_index, path_type, index), location_map)}")
                    lines.append("")
                    if method.client_streaming and method.server_streaming:
                        raise NotImplemented("No generation method for method type: bidirectional stream!")
                    elif method.client_streaming:
                        raise NotImplemented("No generation method for method type: client stream!")
                    elif method.server_streaming:
                        lines.append(f"    async def execute(self):")
                        lines.append(f"        request = {service.name.lower()}_proto.{method.name}Request()")
                        lines.append(f"        ParseDict(asdict(self), request)")
                        lines.append(f"        request.request.timestamp.CopyFrom(ProtoTimestamp().GetCurrentTime())")
                        lines.append(f"        responses = []")
                        lines.append(f"        async for response in self.context['{service.name}'].{method.name}(request):")
                        lines.append(f"            responses.append(response)")
                        lines.append(f"        return {method.name}Response(")
                        lines.append(f"            **MessageToDict(responses[-1], preserving_proto_field_name=True, use_integers_for_enums=True)")
                        lines.append(f"        )")
                    else:
                        lines.append(f"    async def execute(self):")
                        lines.append(f"        request = {service.name.lower()}_proto.{method.name}Request()")
                        lines.append(f"        request.request.timestamp.CopyFrom(ProtoTimestamp().GetCurrentTime())")
                        lines.append(f"        ParseDict(asdict(self), request)")
                        lines.append(f"        response = await self.context['{service.name}'].{method.name}(request)")
                        lines.append(f"        return {method.name}Response(")
                        lines.append(f"            **MessageToDict(response, preserving_proto_field_name=True, use_integers_for_enums=True)")
                        lines.append(f"        )")
                    lines.append("")
            f.writelines("\n".join(lines))

def get_fields(fields):
    result = []
    # Convert the protobuf enum type to a Pythonic type
    for i, field in enumerate(fields):
        # This represents where the field is located in the Protobuf file path
        # NOTE: In future, can be modified to support nested enums and messages
        path_type = 2
        if field.type in [1, 2]: 
            typ = 'float'
        elif field.type in [3, 4, 5, 6, 7, 13, 15, 16, 17, 18]:
            typ = 'int'
        elif field.type == 8:
            typ = 'bool'
        elif field.type == 9:
            typ = 'str'
        elif field.type == 12:
            typ = 'bytes'
        elif field.type in [11, 14]:
            # Named field defined within this file
            typ = field.type_name.split('.')[-1]
            if typ == 'Request':
                continue # Skip request typed fields because they aren't in the Python API
        else:
            typ = 'any'
        if field.proto3_optional == 1: # This is an optional field!
            typ = f'Optional[{typ}]'
        
        result.append((field.name, typ, path_type, i))
    return result

def get_comments(path, location_map):
    comments = []
    leading_comments = location_map.get(path).leading_comments.strip()
    if leading_comments:
        comments.append(leading_comments.replace('\n', ''))
    trailing_comments = location_map.get(path).trailing_comments.strip()
    if trailing_comments:
        comments.append(trailing_comments.replace('\n', ''))
    if len(comments):
        return f"'''{'. '.join(comments)}'''"
    else:
        return ""

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Pydantic type generation file from a base Protobuf protocol.")
    parser.add_argument('--output', type=str, help='Path to the output directory.', default='./types')
    args = parser.parse_args()
    generate(args.output)
