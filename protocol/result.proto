// SPDX-FileCopyrightText: 2025 Carnegie Mellon University - Living Edge Lab
//
// SPDX-License-Identifier: GPL-2.0-only

syntax = "proto3";
package protocol.result;

import "common.proto";
import "google/protobuf/timestamp.proto";


/*
 * Defines the upper left and lower right corners of a detected object
 * in an image frame. Origin (0,0) is the top left corner of the input image.
 * (image_height, image_width) is the bottom right corner.
 * Also the class and confidence threshold associated with the box.
 */
message BoundingBox {
  double y_min = 1; // wrt to image size
  double x_min = 2; // wrt to image size
  double y_max = 3; // wrt to image size
  double x_max = 4; // wrt to image size
  string class_name = 5;
  float confidence = 6;
}

/*
 * Color filter represented by hue, saturation, and value
 * Uses OpenCV ranges: https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html
 */
message HSV {
  uint32 h = 1; // hue range is [0,179]
  uint32 s = 2; // saturation range is [0,255]
  uint32 v = 3; // value range is [0,255]
}

/*
 * Compute results generated by datasink modules
 */
message FrameResult {
  string type = 1;
  uint64 frame_id = 2; // For correlation
  repeated ComputeResult result = 3;
}

message Detection {
  uint64 detection_id = 1; // Can be multiple objects per frame
  string class_name = 2;
  double score = 3;
  BoundingBox bbox = 4;
  bool hsv_filter_passed = 5;
}

message DetectionResult {
  repeated Detection detections = 1;
}

message AvoidanceResult {
  double actuation_vector = 1; // Actuation vector towards safe area
}

message SLAMResult {
  oneof position {
    protocol.common.Position relative_position = 1;
    protocol.common.Location global_position = 2;
  }
}

message ComputeResult {
  google.protobuf.Timestamp timestamp = 1; // Inference timestamp
  string engine_name = 2;
  oneof type {
    DetectionResult detection_result = 3;
    AvoidanceResult avoidance_result = 4;
    SLAMResult slam_result = 5;
    string generic_result = 6; // JSON result
  }
}
